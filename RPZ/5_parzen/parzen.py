#!/usr/bin/python
# -*- coding: utf-8 -*-

import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm, multivariate_normal


# x_range, xA, h
def my_parzen(x, x_trn, h):
    """
    p = my_parzen(x, x_trn, h)

    Parzen window density estimation with normal kernel N(0, h^2).

    :param x:       vector of data points where the probability density functions
                    should be evaluated, (n,) np array
    :param x_trn:   training data (m,) np array
    :param h:       kernel bandwidth, python float
    :return p:      estimated p(x|k) evaluated at values given by x (n,) np array
    """
    X, X_trn = np.meshgrid(x, x_trn)
    kernel = norm.pdf((X_trn - X)/h)/h
    p = np.mean(kernel, axis=0)
    return p


def my_parzen_2d(x, y, x_trn, y_trn, h):
    """
    p = my_parzen(x, x_trn, h)

    Parzen window density estimation with normal kernel N(0, h^2).

    :param x:       vector of data points where the probability density functions
                    should be evaluated, (n,) np array
    :param y:       vector of data points where the probability density functions
                    should be evaluated, (n,) np array
    :param x_trn:   training data (m,) np array
    :param y_trn:   training data (m,) np array
    :param h:       kernel bandwidth, python float
    :return p:      estimated p(x|k) evaluated at values given by x (n,) np array (now - matrix (n,n))
    """
    n = x.size
    x, y = np.meshgrid(x, y)
    X, X_trn = np.meshgrid(x.flatten(), x_trn)
    Y, Y_trn = np.meshgrid(y.flatten(), y_trn)
    kernel = norm.pdf((X_trn - X) / h) / h * norm.pdf((Y_trn - Y) / h) / h
    p = np.reshape(np.mean(kernel, axis=0), (n, n))
    return p


def compute_Lh(itrn, itst, x, h):
    """
    Lh = compute_Lh(itrn, itst, x, h)

    Computes the average log-likelihood over training/test splits generated
    by crossval for a fixed kernel bandwidth h.

    :param itrn:    LIST of (n,) np arrays data splits (indices) generated by crossval()
    :param itst:    LIST of (m,) np arrays data splits (indices) generated by crossval()
    :param x:       input data (n+m,) np array
    :param h:       kernel bandwidth, python float
    :return Lh:     average log-likelihood over training/test splits, python float
    """
    L = np.array([np.sum(np.log(my_parzen(x[itst[i]], x[itrn[i]], h))) for i in range(10)])
    Lh = float(np.mean(L))
    return Lh


def compute_Lh_2d(itrn, itst, x, y, h):
    """
    Lh = compute_Lh(itrn, itst, x, h)

    Computes the average log-likelihood over training/test splits generated
    by crossval for a fixed kernel bandwidth h.

    :param itrn:    LIST of (n,) np arrays data splits (indices) generated by crossval()
    :param itst:    LIST of (m,) np arrays data splits (indices) generated by crossval()
    :param x:       input data (n+m,) np array
    :param h:       kernel bandwidth, python float
    :return Lh:     average log-likelihood over training/test splits, python float
    """
    L = np.zeros(10)
    for i in range(10):
        p_estim = my_parzen_2d(x[itst[i]], y[itst[i]], x[itrn[i]], y[itrn[i]], h)
        L[i] = np.sum(np.log(p_estim.flatten()))
    Lh = float(np.mean(L))
    return Lh


def classify_bayes_parzen(x_test, xA, xC, pA, pC, h_bestA, h_bestC):
    """
    labels = classify_bayes_parzen(x_test, xA, xC, pA, pC, h_bestA, h_bestC)

    Classifies data using bayesian classifier with densities estimated by
    Parzen window estimator.

    :param x_test:  data (measurements) to be classified (n,) np array
    :param xA:      training data for Parzen window for class A (n_xA,) np array
    :param xC:      training data for Parzen window for class C (n_xC,) np array
    :param pA:      prior probability for class A, python float
    :param pC:      prior probability for class C, python float
    :param h_bestA: optimal value of the kernel bandwidth, python float
    :param h_bestC: optimal value of the kernel bandwidth, python float
    :return labels: classification labels for x_test (n,) np array
    """
    estimated_pA = my_parzen(x_test, xA, h_bestA)
    estimated_pC = my_parzen(x_test, xC, h_bestC)
    labels = np.where(estimated_pA * pA > estimated_pC * pC, 0, 1)
    return labels


def classify_bayes_parzen_2d(x_test, y_test, xA, xC, yA, yC, pA, pC, h_bestA, h_bestC):
    """
    labels = classify_bayes_parzen(x_test, xA, xC, pA, pC, h_bestA, h_bestC)

    Classifies data using bayesian classifier with densities estimated by
    Parzen window estimator.

    :param x_test:  data (measurements) to be classified (n,) np array
    :param xA:      training data for Parzen window for class A (n_xA,) np array
    :param xC:      training data for Parzen window for class C (n_xC,) np array
    :param pA:      prior probability for class A, python float
    :param pC:      prior probability for class C, python float
    :param h_bestA: optimal value of the kernel bandwidth, python float
    :param h_bestC: optimal value of the kernel bandwidth, python float
    :return labels: classification labels for x_test (n,) np array
    """
    estimated_pA = my_parzen_2d(x_test, y_test, xA, yA, h_bestA)
    estimated_pC = my_parzen_2d(x_test, y_test, xC, yC, h_bestC)
    estimated_pA = estimated_pA.diagonal()
    estimated_pC = estimated_pC.diagonal()
    labels = np.where(estimated_pA * pA > estimated_pC * pC, 0, 1)
    return labels


################################################################################
#####                                                                      #####
#####             Below this line are already prepared methods             #####
#####                                                                      #####
################################################################################


def show_classification(test_images, labels, letters):
    """
    show_classification(test_images, labels, letters)

    create montages of images according to estimated labels

    :param test_images:     np.array (h, w, n)
    :param labels:          labels for input images np.array (n,)
    :param letters:         string with letters, e.g. 'CN'
    """

    def montage(images, colormap='gray'):
        """
        Show images in grid.

        :param images:      np.array (h, w, n)
        :param colormap:    numpy colormap
        """
        h, w, count = np.shape(images)
        h_sq = np.int(np.ceil(np.sqrt(count)))
        w_sq = h_sq
        im_matrix = np.zeros((h_sq * h, w_sq * w))

        image_id = 0
        for j in range(h_sq):
            for k in range(w_sq):
                if image_id >= count:
                    break
                slice_w = j * h
                slice_h = k * w
                im_matrix[slice_h:slice_h + w, slice_w:slice_w + h] = images[:, :, image_id]
                image_id += 1
        plt.imshow(im_matrix, cmap=colormap)
        plt.axis('off')
        return im_matrix

    for i in range(len(letters)):
        imgs = test_images[:,:,labels==i]
        subfig = plt.subplot(1,len(letters),i+1)
        montage(imgs)
        plt.title(letters[i])


def crossval(num_data, num_folds):
    """
    itrn, itst = crossval(num_data, num_folds)

    Partitions data for cross-validation.

    This function randomly partitions data into the training
    and testing parts. The number of partitioning is determined
    by the num_folds. If num_folds==1 then makes only one random
    partitioning of data into training and testing in ratio 50:50.

    :param num_data:    number of data (scalar, integer)
    :param num_folds:   number of folders (scalar, integer)
    :return itrn:       itrn - LIST of training folds, itst - LIST of testing folds
                            itrn[i] indices of training data of i-th folder (n,) np array
                            itst[i] indices of testing data of i-th folder (n,) np array
    """
    if num_folds < 2:
        print("Minimal number of folds set to 2.")
        num_folds = 2

    inx = np.random.permutation(num_data)

    itrn = []
    itst = []

    num_column = np.int32(np.ceil(np.float64(num_data) / num_folds))

    for idx in range(num_folds):
        tst_idx = range((idx * num_column), np.min([num_data, ((idx + 1) * num_column)]))
        trn_idx = [i for i in list(range(num_data)) if i not in tst_idx]
        itst.append(inx[tst_idx])
        itrn.append(inx[trn_idx])
    return itrn, itst


def compute_measurement_lr_cont(imgs):
    """
    x = compute_measurement_lr_cont(imgs)

    Compute measurement on images, subtract sum of right half from sum of
    left half.

    :param imgs:    set of images, (h, w, n)
    :return:        measurements, (n, )
    """
    assert len(imgs.shape) == 3

    width = imgs.shape[1]
    sum_rows = np.sum(imgs, dtype=np.float64, axis=0)

    x = np.sum(sum_rows[0:int(width / 2),:], axis=0) - np.sum(sum_rows[int(width / 2):,:], axis=0)

    assert x.shape == (imgs.shape[2], )
    return x


def compute_measurement_ul_cont(imgs):
    """
    x = compute_measurement_ul_cont(imgs)

    Compute measurement on images, subtract sum of op half from sum of
    bottom half.

    :param imgs:    set of images, (h, w, n) numpy array
    :return x:      measurements, (n, ) numpy array
    """
    assert len(imgs.shape) == 3

    h = imgs.shape[0]
    sum_columns = np.sum(imgs, dtype=np.float64, axis=1)

    x = np.sum(sum_columns[0:int(h / 2), :], axis=0) - np.sum(sum_columns[int(h / 2):, :], axis=0)

    assert x.shape == (imgs.shape[2],)
    return x
